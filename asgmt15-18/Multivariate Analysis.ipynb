{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate analysis: Predictive models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting sources: \n",
    "- https://learn.datacamp.com/courses/machine-learning-with-tree-based-models-in-python\n",
    "- https://www.datacamp.com/community/tutorials/decision-tree-classification-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/media/overview/tdsp-lifecycle2.png \"Data Science Lifecycle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen that we can uncover correlations by using bivariate analyis. This also raises the question: If we extract information from multiple columns (Multivariate analysis), could we use these correlations to calculate/predict the value of a column for rows that do not yet have a value?\n",
    "\n",
    "For example:\n",
    "- Can we calculate if a customer will churn (= We lose the customer)?\n",
    "- Can we calculate if a customer would use a certain product? (Product recommendation)\n",
    "- Can we calculate if a mail is spam or not?\n",
    "- Can we calculate if a financial transaction is fraudulent or not?\n",
    "- Can we calculate if a customer will be able to pay back their loan or not?\n",
    "- Can we calculate the price people are willing to pay for a house?\n",
    "- Can we calculate the salary a student will earn in the future?\n",
    "- ...\n",
    "\n",
    "Just as we used math/statistics to support to explore the data one column at a time (Univariate) and per combination of two columns (Bivariate analysis), we will use machine learning algorithms to extract information across multiple columns (Multivariate analysis) and to build data products. \n",
    "\n",
    "Machine learning is:\n",
    "- Machine learning is a method of data analysis that automates analytical model building. It is a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention. (https://www.sas.com/en_us/insights/analytics/machine-learning.html#:~:text=Machine%20learning%20is%20a%20method,decisions%20with%20minimal%20human%20intervention.)\n",
    "- Machine learning (ML) is the study of computer algorithms that improve automatically through experience.[1] It is seen as a part of artificial intelligence. Machine learning algorithms build a model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to do so.[2] Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks. (https://en.wikipedia.org/wiki/Machine_learning)\n",
    "\n",
    "Examples of data products could include:\n",
    "- A product recommender\n",
    "- A customer churn predictor\n",
    "- A mail labeler (Primary, promotion, social, spam, etc.)\n",
    "- Sentiment analyser for social media messages\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/1204/1*qYoU2VTBsORAfhkfiluURQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will refer to the column that we are trying to calculate as the <b>target variable</b>. The columns used for this calculation will be refered to as the <b>feature variables</b>.\n",
    "\n",
    "For example, if we want to predict a person's shoe size based on their body length:\n",
    "- The shoe size is the target variable\n",
    "- The body length is the feature variable\n",
    "\n",
    "Extra info: The terms 'target' and 'feature' are borrowed from the field of Machine Learning. In the field of statistics, we refer to the target variable as the dependent variable and we refer to the feature variables as the independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the target variable is a categorical variable then we refer to this task as a classification task.\n",
    "\n",
    "Examples of classification tasks:\n",
    "- Predict if a customer will churn. \n",
    "- Predict if a customer will use a specific product.\n",
    "- Label mails as spam.\n",
    "- Label financial transactions as fraudulent.\n",
    "- Label a social media message as positive, neutral or negative.\n",
    "- Predict if a customer of the bank will be able to pay back the loan.\n",
    "\n",
    "Examples of machine learning algorithms that we could use for classification:\n",
    "- Decision trees\n",
    "- Random forests\n",
    "- Logistic regression\n",
    "- Neural networks\n",
    "- Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset(\"iris\")\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/1000/1*Hh53mOF4Xy4eORjLilKOwA.png \"Iris dataset\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.species.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features= ['sepal_length']\n",
    "dt = DecisionTreeClassifier(max_depth = 1) # Increase max_depth to see effect in the plot\n",
    "dt.fit(iris[features], iris['species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`conda install -c anaconda graphviz`  \n",
    "`conda install -c anaconda python-graphviz`  \n",
    "`conda install -c anaconda pydot`  \n",
    "If the code below still does not work, install from here: (https://graphviz.org/download/)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "def plot_tree_classification(model, features, class_names):\n",
    "    # Generate plot data\n",
    "    dot_data = tree.export_graphviz(model, out_file=None, \n",
    "                          feature_names=features,  \n",
    "                          class_names=class_names,  \n",
    "                          filled=True, rounded=True,  \n",
    "                          special_characters=True)  \n",
    "\n",
    "    # Turn into graph using graphviz\n",
    "    graph = graphviz.Source(dot_data)  \n",
    "\n",
    "    # Write out a pdf\n",
    "    graph.render(\"decision_tree\")\n",
    "\n",
    "    # Display in the notebook\n",
    "    return graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree_classification(dt, features, iris.species.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to turn this into a data product, then we must know how well our model performs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dt.predict(iris[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(predictions, actuals):\n",
    "    if(len(predictions) != len(actuals)):\n",
    "        raise Exception(\"The amount of predictions did not equal the amount of actuals\")\n",
    "    \n",
    "    return (predictions == actuals).sum() / len(actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_accuracy(predictions, iris.species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note:</b> Using accuracy is actually not the best way to evaluate a classification model. However, for this course it will serve as a easy-to-understand first measurement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating our model on the same data that it was trained on, actually provides an overoptimistic estimate of our model's performance. Our intent is to use our model on data that it has not yet seen before, so we should evaluate our model in the same way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test/train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_train, iris_test = train_test_split(iris, test_size=0.3, stratify=iris['species'], random_state=42)\n",
    "print(iris_train.shape, iris_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features= ['sepal_length']\n",
    "dt_classification = DecisionTreeClassifier(max_depth = 1) # Increase max_depth to see effect in the plot\n",
    "dt_classification.fit(iris_train[features], iris_train['species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsOnTrainset = dt_classification.predict(iris_train[features])\n",
    "predictionsOnTestset = dt_classification.predict(iris_test[features])\n",
    "\n",
    "accuracyTrain = calculate_accuracy(predictionsOnTrainset, iris_train.species)\n",
    "accuracyTest = calculate_accuracy(predictionsOnTestset, iris_test.species)\n",
    "\n",
    "print(\"Accuracy on training set \" + str(accuracyTrain))\n",
    "print(\"Accuracy on test set \" + str(accuracyTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio assignment 15\n",
    "30 min: Train a decision tree to predict the species of a penguin based on their characteristics.\n",
    "- Split the penguin dataset into a train (70%) and test (30%) set.\n",
    "- Use the train set to fit a DecisionTreeClassifier. You are free to to choose which columns you want to use as feature variables and you are also free to choose the max_depth of the tree. \n",
    "<b>Note</b>: Some machine learning algorithms can not handle missing values. You will either need to \n",
    " - replace missing values (with the mean or most popular value). For replacing missing values you can use .fillna(\\<value\\>) https://pandas.pydata.org/docs/reference/api/pandas.Series.fillna.html\n",
    " - remove rows with missing data.  You can remove rows with missing data with .dropna() https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html\n",
    "- Use your decision tree model to make predictions for both the train and test set.\n",
    "- Calculate the accuracy for both the train set predictions and test set predictions.\n",
    "- Is the accurracy different? Did you expect this difference?\n",
    "- Use the plot_tree_classification function above to create a plot of the decision tree. Take a few minutes to analyse the decision tree. Do you understand the tree?\n",
    "\n",
    "Optional: Perform the same tasks but try to predict the sex of the pinguin based on the other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = sns.load_dataset(\"penguins\")\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/0v1CGNV.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy on test and train set\n",
    "\n",
    "calculating accuracy on the same set that was used to train will result in a higher accuracy. A higher depth will build a decision tree better suited for the train set, which means that the accuracy for the train set will rise significantly, while the accuracy for the test set will drop after a certain depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['body_mass_g']\n",
    "penguins = penguins.dropna()\n",
    "penguins_train, penguins_test = train_test_split(penguins, test_size=0.3, stratify=penguins['island'], random_state=123)\n",
    "dt = DecisionTreeClassifier(max_depth=5)\n",
    "dt.fit(penguins_train[features], penguins_train['island'])\n",
    "\n",
    "testPrediction = dt.predict(penguins_test[features])\n",
    "trainPrediction = dt.predict(penguins_train[features])\n",
    "\n",
    "print(f'test set acc ({calculate_accuracy(testPrediction, penguins_test.island)})')\n",
    "print(f'train set acc ({calculate_accuracy(trainPrediction, penguins_train.island)})')\n",
    "\n",
    "plot_tree_classification(dt, features, penguins.species.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio assignment 16\n",
    "30 min: Train a decision tree to predict one of the categorical columns of your own dataset.\n",
    "- Split your dataset into a train (70%) and test (30%) set.\n",
    "- Use the train set to fit a DecisionTreeClassifier. You are free to to choose which columns you want to use as feature variables and you are also free to choose the max_depth of the tree. \n",
    "- Use your decision tree model to make predictions for both the train and test set.\n",
    "- Calculate the accuracy for both the train set predictions and test set predictions.\n",
    "- Is the accurracy different? Did you expect this difference?\n",
    "- Use the plot_tree function above to create a plot of the decision tree. Take a few minutes to analyse the decision tree. Do you understand the tree?\n",
    "    \n",
    "![](https://i.imgur.com/0v1CGNV.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the target variable is a numerical variable then we refer to this task as a regression task.\n",
    "\n",
    "Examples of regression tasks:\n",
    "- Predict the price people are willing to pay for a house.\n",
    "- Predict the salary a student will earn in the future.\n",
    "\n",
    "Examples of machine learning algorithms that we could use for regression:\n",
    "- Decision trees\n",
    "- Random forests\n",
    "- Linear regression\n",
    "- Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features= ['petal_length']\n",
    "dt_regression = DecisionTreeRegressor(max_depth = 1) # Increase max_depth to see effect in the plot\n",
    "dt_regression.fit(iris_train[features], iris_train['sepal_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "def plot_tree_regression(model, features):\n",
    "    # Generate plot data\n",
    "    dot_data = tree.export_graphviz(model, out_file=None, \n",
    "                          feature_names=features,  \n",
    "                          filled=True, rounded=True,  \n",
    "                          special_characters=True)  \n",
    "\n",
    "    # Turn into graph using graphviz\n",
    "    graph = graphviz.Source(dot_data)  \n",
    "\n",
    "    # Write out a pdf\n",
    "    graph.render(\"decision_tree\")\n",
    "\n",
    "    # Display in the notebook\n",
    "    return graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree_regression(dt_regression, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For regression we often use Root Mean Square Error (RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://www.aimlfront.com/images/rmse1.png \"RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(predictions, actuals):\n",
    "    if(len(predictions) != len(actuals)):\n",
    "        raise Exception(\"The amount of predictions did not equal the amount of actuals\")\n",
    "    \n",
    "    return (((predictions - actuals) ** 2).sum() / len(actuals)) ** (1/2)\n",
    "\n",
    "## The same function but using a for-loop instead of a vectorized operation. \n",
    "# def calculate_rmse(predictions, actuals):\n",
    "#    if(len(predictions) != len(actuals)):\n",
    "#        raise Exception(\"The amount of predictions did not equal the amount of actuals\")\n",
    "#    \n",
    "#    diffSquared = 0\n",
    "#    \n",
    "#    for prediction_i, actual_i in zip(predictions, actuals):\n",
    "#        diffSquared += (prediction_i - actual_i)**2\n",
    "#        \n",
    "#    return (diffSquared/len(actuals))**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictionsOnTrainset = dt_regression.predict(iris_train[features])\n",
    "predictionsOnTestset = dt_regression.predict(iris_test[features])\n",
    "\n",
    "rmseTrain = calculate_rmse(predictionsOnTrainset, iris_train.sepal_length)\n",
    "rmseTest = calculate_rmse(predictionsOnTestset, iris_test.sepal_length)\n",
    "\n",
    "print(\"RMSE on training set \" + str(rmseTrain))\n",
    "print(\"RMSE on test set \" + str(rmseTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio assignment 17\n",
    "30 min: Train a decision tree to predict the body_mass_g of a penguin based on their characteristics.\n",
    "- Split the penguin dataset into a train (70%) and test (30%) set.\n",
    "- Use the train set to fit a DecisionTreeRegressor. You are free to to choose which columns you want to use as feature variables and you are also free to choose the max_depth of the tree. \n",
    "<b>Note</b>: Some machine learning algorithms can not handle missing values. You will either need to \n",
    " - replace missing values (with the mean or most popular value). For replacing missing values you can use .fillna(\\<value\\>) https://pandas.pydata.org/docs/reference/api/pandas.Series.fillna.html\n",
    " - remove rows with missing data.  You can remove rows with missing data with .dropna() https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html\n",
    "- Use your decision tree model to make predictions for both the train and test set.\n",
    "- Calculate the RMSE for both the train set predictions and test set predictions.\n",
    "- Is the RMSE different? Did you expect this difference?\n",
    "- Use the plot_tree_regression function above to create a plot of the decision tree. Take a few minutes to analyse the decision tree. Do you understand the tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = sns.load_dataset(\"penguins\")\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/0v1CGNV.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio assignment 18\n",
    "30 min: Train a decision tree to predict one of the numerical columns of your own dataset.\n",
    "- Split your dataset into a train (70%) and test (30%) set.\n",
    "- Use the train set to fit a DecisionTreeRegressor. You are free to to choose which columns you want to use as feature variables and you are also free to choose the max_depth of the tree. \n",
    "- Use your decision tree model to make predictions for both the train and test set.\n",
    "- Calculate the accuracy for both the train set predictions and test set predictions.\n",
    "- Is the accurracy different? Did you expect this difference?\n",
    "- Use the plot_tree function above to create a plot of the decision tree. Take a few minutes to analyse the decision tree. Do you understand the tree?\n",
    "    \n",
    "![](https://i.imgur.com/0v1CGNV.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
